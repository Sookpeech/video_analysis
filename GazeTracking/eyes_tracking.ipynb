{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd1a67cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "민감도를 입력해주세요.(1 ~ 10) : 10\n",
      "영상 길이 : 0:16.5\n",
      "분석에 걸린 시간 :  10.501588582992554\n",
      "fps :  24\n",
      "시선이 분산된 시간(대본) :  3.175\n",
      "시선이 분산된 시간(주변) :  3.5\n",
      "얼굴 움직임 시간 :  0.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from gaze_tracking import GazeTracking\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "gaze = GazeTracking()\n",
    "# webcam = cv2.VideoCapture(0)\n",
    "\n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "sensitivity = int(input(\"민감도를 입력해주세요.(1 ~ 10) : \"))\n",
    "\n",
    "cap = cv2.VideoCapture('C:/Users/82109/Videos/eye.mp4')\n",
    "if cap.isOpened()==False:\n",
    "    print(\"동영상 불러오기에 실패했습니다.\")\n",
    "    \n",
    "\n",
    "FPS = int(cap.get(cv2.CAP_PROP_FPS)) # 동영상의 fps 알아냄\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # 전체 frame 알아냄\n",
    "duration = frame_count/FPS # fps와 전체 frame 수로 동영상 길이 알아냄\n",
    "pTime = 0\n",
    "\n",
    "# 자세가 바르지 않은 시간을 세는 변수\n",
    "count = 0\n",
    "# 각 제스처를 몇 초동안 했는지 세는 변수\n",
    "eye_count = 0 # 주변\n",
    "face_count = 0 # 얼굴\n",
    "script_count = 0 # 대본\n",
    "# 프레임 변수\n",
    "f_count = 0\n",
    "\n",
    "# face\n",
    "f_before = 0\n",
    "f_present = 0\n",
    "\n",
    "# script\n",
    "s_before = 0\n",
    "s_present = 0\n",
    "\n",
    "# face movement\n",
    "m_before = 0\n",
    "m_present = 0\n",
    "# 눈 깜박임 횟수 보정값\n",
    "correction = duration / 20\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "while True:\n",
    "    # We get a new frame from the webcam\n",
    "    _, img = cap.read()\n",
    "    \n",
    "    # 원하는 프레임 단위로 cut\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES,f_count/2);\n",
    "#     print(index)\n",
    "    f_count += FPS\n",
    "    \n",
    "    # 동영상이 끝나면 break\n",
    "    if (np.shape(img) == ()): break\n",
    "        \n",
    "    # We send this frame to GazeTracking to analyze it\n",
    "    gaze.refresh(img)\n",
    "\n",
    "    new_img = gaze.annotated_frame()\n",
    "    text = \"\"\n",
    "    \n",
    "    if m_before == m_present and m_present == 1:\n",
    "        face_count += FPS/2\n",
    "            \n",
    "    if f_before == f_present and f_present == 1:\n",
    "        eye_count += FPS/2\n",
    "            \n",
    "    if s_before == s_present and s_present == 1:\n",
    "        script_count += FPS/2\n",
    "            \n",
    "    f_before = f_present\n",
    "    s_before = s_present\n",
    "    m_before = m_present\n",
    "\n",
    "    if gaze.is_blinking():\n",
    "        s_present = 1\n",
    "        text = \"Blinking\"\n",
    "    else:\n",
    "        s_present = 0\n",
    "        \n",
    "    if gaze.is_right():\n",
    "        f_present = 1\n",
    "        text = \"Looking right\"\n",
    "    elif gaze.is_left():\n",
    "        f_present = 1\n",
    "        text = \"Looking left\"\n",
    "    else:\n",
    "        f_present = 0\n",
    "    if gaze.is_center():\n",
    "        text = \"Looking center\"\n",
    "        \n",
    "\n",
    "    cv2.putText(new_img, text, (10, 60), cv2.FONT_HERSHEY_DUPLEX, 1.6, (147, 58, 31), 2)\n",
    "\n",
    "    left_pupil = gaze.pupil_left_coords()\n",
    "    right_pupil = gaze.pupil_right_coords()\n",
    "    cv2.putText(new_img, \"Left pupil:  \" + str(left_pupil), (10, 130), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
    "    cv2.putText(new_img, \"Right pupil: \" + str(right_pupil), (10, 165), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
    "    cv2.namedWindow('Demo', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Demo\", new_img)\n",
    "\n",
    "    \n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imgRGB)\n",
    "    \n",
    "    nose = results.pose_landmarks.landmark[0]\n",
    "    \n",
    "    if results.pose_landmarks:\n",
    "        mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "\n",
    "# 얼굴 움직임 분석\n",
    "        if (abs(nose.x - 0.5) >= (11 - sensitivity) * 0.1):\n",
    "            m_present = 1\n",
    "            print(\"얼굴 움직임\")\n",
    "#             cv2.putText(img, \"Please adjust your body to the standard.\", (100,50), cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0), 3)\n",
    "        else:\n",
    "            m_present = 0\n",
    "\n",
    "            \n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    pTime = cTime\n",
    "\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    # 웹캠 이용시 q 입력하면 끔\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "end = time.time()\n",
    "cap.release()\n",
    "cv2.destroyWindow(\"Demo\")\n",
    "\n",
    "minutes = int(duration / 60)\n",
    "seconds = duration % 60\n",
    "\n",
    "print(\"영상 길이 : \" + str(minutes) + ':' + str(seconds))\n",
    "print(\"분석에 걸린 시간 : \", (end - start))\n",
    "print(\"fps : \", FPS)\n",
    "\n",
    "if (script_count/FPS - correction > 0):\n",
    "    print(\"시선이 분산된 시간(대본) : \", script_count/FPS - correction)\n",
    "print(\"시선이 분산된 시간(주변) : \", eye_count/FPS)\n",
    "print(\"얼굴 움직임 시간 : \", face_count/FPS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfe9dd",
   "metadata": {},
   "source": [
    "# frame cut X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dcdad47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "민감도를 입력해주세요.(1 ~ 10) : 10\n",
      "영상 길이 : 0:16.5\n",
      "분석에 걸린 시간 :  31.190959930419922\n",
      "fps :  24\n",
      "시선이 분산된 시간(대본) :  4.3\n",
      "시선이 분산된 시간(주변) :  4.958333333333333\n",
      "얼굴 움직임 시간 :  0.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from gaze_tracking import GazeTracking\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "gaze = GazeTracking()\n",
    "# webcam = cv2.VideoCapture(0)\n",
    "\n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "sensitivity = int(input(\"민감도를 입력해주세요.(1 ~ 10) : \"))\n",
    "\n",
    "cap = cv2.VideoCapture('C:/Users/82109/Videos/eye.mp4')\n",
    "if cap.isOpened()==False:\n",
    "    print(\"동영상 불러오기에 실패했습니다.\")\n",
    "    \n",
    "\n",
    "FPS = int(cap.get(cv2.CAP_PROP_FPS)) # 동영상의 fps 알아냄\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # 전체 frame 알아냄\n",
    "duration = frame_count/FPS # fps와 전체 frame 수로 동영상 길이 알아냄\n",
    "pTime = 0\n",
    "\n",
    "# 자세가 바르지 않은 시간을 세는 변수\n",
    "count = 0\n",
    "# 각 제스처를 몇 초동안 했는지 세는 변수\n",
    "eye_count = 0 # 주변\n",
    "face_count = 0 # 얼굴\n",
    "script_count = 0 # 대본\n",
    "# 프레임 변수\n",
    "f_count = 0\n",
    "\n",
    "# face\n",
    "f_before = 0\n",
    "f_present = 0\n",
    "\n",
    "# script\n",
    "s_before = 0\n",
    "s_present = 0\n",
    "\n",
    "# face movement\n",
    "m_before = 0\n",
    "m_present = 0\n",
    "# 눈 깜박임 횟수 보정값\n",
    "correction = duration / 20\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "while True:\n",
    "    # We get a new frame from the webcam\n",
    "    _, img = cap.read()\n",
    "    \n",
    "    # 원하는 프레임 단위로 cut\n",
    "#     cap.set(cv2.CAP_PROP_POS_FRAMES,f_count/2);\n",
    "#     print(index)\n",
    "    f_count += FPS\n",
    "    \n",
    "    # 동영상이 끝나면 break\n",
    "    if (np.shape(img) == ()): break\n",
    "        \n",
    "    # We send this frame to GazeTracking to analyze it\n",
    "    gaze.refresh(img)\n",
    "\n",
    "    new_img = gaze.annotated_frame()\n",
    "    text = \"\"\n",
    "    \n",
    "#     if m_before == m_present and m_present == 1:\n",
    "#         face_count += FPS/2\n",
    "            \n",
    "#     if f_before == f_present and f_present == 1:\n",
    "#         eye_count += FPS/2\n",
    "            \n",
    "#     if s_before == s_present and s_present == 1:\n",
    "#         script_count += FPS/2\n",
    "            \n",
    "#     f_before = f_present\n",
    "#     s_before = s_present\n",
    "#     m_before = m_present\n",
    "\n",
    "    if gaze.is_blinking():\n",
    "        script_count += 1\n",
    "        text = \"Blinking\"\n",
    "#     else:\n",
    "#         s_present = 0\n",
    "        \n",
    "    if gaze.is_right():\n",
    "        f_present = 1\n",
    "        eye_count += 1\n",
    "        text = \"Looking right\"\n",
    "    elif gaze.is_left():\n",
    "        f_present = 1\n",
    "        eye_count += 1\n",
    "        text = \"Looking left\"\n",
    "#     else:\n",
    "#         f_present = 0\n",
    "    if gaze.is_center():\n",
    "        text = \"Looking center\"\n",
    "        \n",
    "\n",
    "    cv2.putText(new_img, text, (10, 60), cv2.FONT_HERSHEY_DUPLEX, 1.6, (147, 58, 31), 2)\n",
    "\n",
    "    left_pupil = gaze.pupil_left_coords()\n",
    "    right_pupil = gaze.pupil_right_coords()\n",
    "    cv2.putText(new_img, \"Left pupil:  \" + str(left_pupil), (10, 130), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
    "    cv2.putText(new_img, \"Right pupil: \" + str(right_pupil), (10, 165), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
    "    cv2.namedWindow('Demo', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Demo\", new_img)\n",
    "\n",
    "    \n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imgRGB)\n",
    "    \n",
    "    nose = results.pose_landmarks.landmark[0]\n",
    "    \n",
    "    if results.pose_landmarks:\n",
    "        mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "\n",
    "# 얼굴 움직임 분석\n",
    "        if (abs(nose.x - 0.5) >= (11 - sensitivity) * 0.1):\n",
    "            m_present = 1\n",
    "            print(\"얼굴 움직임\")\n",
    "            face_count += 1\n",
    "#             cv2.putText(img, \"Please adjust your body to the standard.\", (100,50), cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0), 3)\n",
    "        else:\n",
    "            m_present = 0\n",
    "\n",
    "            \n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    pTime = cTime\n",
    "\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    # 웹캠 이용시 q 입력하면 끔\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "end = time.time()\n",
    "cap.release()\n",
    "cv2.destroyWindow(\"Demo\")\n",
    "\n",
    "minutes = int(duration / 60)\n",
    "seconds = duration % 60\n",
    "\n",
    "print(\"영상 길이 : \" + str(minutes) + ':' + str(seconds))\n",
    "print(\"분석에 걸린 시간 : \", (end - start))\n",
    "print(\"fps : \", FPS)\n",
    "\n",
    "if (script_count/FPS - correction > 0):\n",
    "    print(\"시선이 분산된 시간(대본) : \", script_count/FPS - correction)\n",
    "print(\"시선이 분산된 시간(주변) : \", eye_count/FPS)\n",
    "print(\"얼굴 움직임 시간 : \", face_count/FPS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
