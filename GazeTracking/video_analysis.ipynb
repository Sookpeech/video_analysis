{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3520dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from gaze_tracking import GazeTracking\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47636b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_analysis(sensitivity, video_path):\n",
    "    # 라이브러리 pose 클래스 초기화\n",
    "    mpPose = mp.solutions.pose\n",
    "    pose = mpPose.Pose()\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "    # 비디오 객체 불러오기\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if cap.isOpened()==False:\n",
    "        print(\"동영상 불러오기에 실패했습니다.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 변수 정의\n",
    "    FPS = int(cap.get(cv2.CAP_PROP_FPS)) # 동영상의 fps 알아냄\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # 전체 frame 수 알아냄\n",
    "    duration = frame_count/FPS # fps와 전체 frame 수로 동영상 길이 알아냄\n",
    "\n",
    "    # 자세가 바르지 않은 시간을 세는 변수\n",
    "    count = 0\n",
    "    \n",
    "    # 각 제스처의 시간을 세는 변수\n",
    "    first_count = 0\n",
    "    second_count = 0\n",
    "    third_count = 0\n",
    "    \n",
    "    # 프레임 변수\n",
    "    f_count = 0\n",
    "    \n",
    "    # 자세 불량 flag 변수\n",
    "    p_before = 0; p_present = 0\n",
    "\n",
    "    # 첫번째 제스처 flag 변수\n",
    "    f_before = 0; f_present = 0\n",
    "\n",
    "    # 두 번째 제스처 flag 변수\n",
    "    s_before = 0; s_present = 0\n",
    "\n",
    "    # 세 번째 제스처 flag 변수\n",
    "    t_before = 0; t_present = 0\n",
    "\n",
    "    # 분석 시작 시간\n",
    "    start = time.time()\n",
    "\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "\n",
    "        # 원하는 프레임 단위로 cut\n",
    "        # \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES,f_count/2);\n",
    "        f_count += FPS\n",
    "\n",
    "        # 동영상이 끝나면 break\n",
    "        if (np.shape(img) == ()): break\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(imgRGB)\n",
    "        \n",
    "\n",
    "        # 각 변수에 스켈레톤 저장\n",
    "        left_shoulder = results.pose_landmarks.landmark[11]\n",
    "        right_shoulder = results.pose_landmarks.landmark[12]\n",
    "\n",
    "        left_wrist = results.pose_landmarks.landmark[15]\n",
    "        right_wrist = results.pose_landmarks.landmark[16]\n",
    "\n",
    "        left_elbow = results.pose_landmarks.landmark[13]\n",
    "        right_elbow = results.pose_landmarks.landmark[14]\n",
    "\n",
    "        left_hip = results.pose_landmarks.landmark[23]\n",
    "        right_hip = results.pose_landmarks.landmark[24]\n",
    "\n",
    "        \n",
    "        \n",
    "        # 조건 잡아내기\n",
    "        if results.pose_landmarks:\n",
    "            mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "            \n",
    "            \n",
    "            # 1초 동안 그 행동을 했다고 판단하면 각 count 변수에 더하기\n",
    "            # FPS/2를 하는 이유는 프레임수를 FPS/2로 건너뛰었기 때문에\n",
    "            if p_before == p_present and p_present == 1:\n",
    "                count += FPS/2\n",
    "\n",
    "            if f_before == f_present and f_present == 1:\n",
    "                first_count += FPS/2\n",
    "\n",
    "            if s_before == s_present and s_present == 1:\n",
    "                second_count += FPS/2\n",
    "\n",
    "            if t_before == t_present and t_present == 1:\n",
    "                third_count += FPS/2\n",
    "\n",
    "            # 변수 초기화하기\n",
    "            p_before = p_present\n",
    "            f_before = f_present\n",
    "            s_before = s_present\n",
    "            t_before = t_present\n",
    "\n",
    "\n",
    "    # 자세 분석\n",
    "            if (abs((left_shoulder.x + right_shoulder.x) / 2 - 0.5) >= 0.1):\n",
    "                print(\"몸을 화면 가운데에 맞춰주세요.\")\n",
    "\n",
    "            if (abs(left_shoulder.y - right_shoulder.y) >= (11 - sensitivity) * 0.01):\n",
    "    #             print(\"두 어깨의 균형이 맞지 않습니다.\")\n",
    "                p_present = 1\n",
    "            else:\n",
    "                p_present = 0\n",
    "\n",
    "    # 제스처 분석\n",
    "    \n",
    "    # 1번: 손이 얼굴 위로 올라갔을 때\n",
    "            if ((left_wrist.x < left_shoulder.x) and (left_wrist.x > right_shoulder.x) \\\n",
    "               and (left_wrist.y < left_shoulder.y)):\n",
    "                f_present = 1\n",
    "\n",
    "            elif ((right_wrist.x < left_shoulder.x) and (right_wrist.x > right_shoulder.x) \\\n",
    "               and (right_wrist.y < right_shoulder.y)):\n",
    "                f_present = 1\n",
    "            else:\n",
    "                f_present = 0\n",
    "\n",
    "    # 2번: 팔짱 끼거나 한 쪽 팔을 잡았을 때, 손 맞잡을 때\n",
    "            if (abs(left_wrist.x - right_shoulder.x) <= sensitivity * 0.05 or abs(left_wrist.x - right_shoulder.x) <= sensitivity * 0.05):\n",
    "                s_present = 1\n",
    "            else:\n",
    "                s_present = 0\n",
    "\n",
    "    # 3번: 허리에 손을 올렸을 때\n",
    "            if (left_wrist.y < left_hip.y and right_wrist.y < right_hip.y):\n",
    "                if (abs(left_wrist.x - left_hip.x) <= sensitivity * 0.01 and (left_hip.y - left_wrist.y) <= sensitivity * 0.005 and abs(right_wrist.x - right_hip.x) <= sensitivity * 0.01 and (right_hip.y - right_wrist.y) <= sensitivity * 0.005):\n",
    "                    t_present = 1\n",
    "                else:\n",
    "                    t_present = 0\n",
    "\n",
    "        cv2.namedWindow('pose', cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"pose\", img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    end = time.time()\n",
    "    cap.release()\n",
    "    cv2.destroyWindow(\"pose\")\n",
    "\n",
    "    minutes = int(duration / 60)\n",
    "    seconds = duration % 60\n",
    "\n",
    "    print(\"영상 길이 : \" + str(minutes) + ':' + str(seconds))\n",
    "    print(\"분석에 걸린 시간 : \", (end - start))\n",
    "    print(\"fps : \", FPS)\n",
    "\n",
    "    print(\"자세가 기울어진 시간 : \", count/FPS)\n",
    "    print(\"1번 제스처 시간 : \", first_count/FPS)\n",
    "    print(\"2번 제스처 시간 : \", second_count/FPS)\n",
    "    print(\"3번 제스처 시간 : \", third_count/FPS)\n",
    "    \n",
    "    return count/FPS, first_count/FPS, second_count/FPS, third_count/FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c758b1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "민감도를 입력해주세요.(1 ~ 10) : 6\n",
      "영상 길이 : 0:33.458333333333336\n",
      "분석에 걸린 시간 :  15.849493980407715\n",
      "fps :  24\n",
      "자세가 기울어진 시간 :  0.0\n",
      "1번 제스처 시간 :  2.5\n",
      "2번 제스처 시간 :  7.0\n",
      "3번 제스처 시간 :  9.5\n",
      "0.0   2.5   7.0   9.5\n"
     ]
    }
   ],
   "source": [
    "# 민감도는 1부터 10까지의 정수\n",
    "sensitivity = int(input(\"민감도를 입력해주세요.(1 ~ 10) : \"))\n",
    "video_path = 'C:/Users/82109/Videos/sample.mp4'\n",
    "\n",
    "pose_time, f_time, s_time, t_time = video_analysis(sensitivity, video_path)\n",
    "print(pose_time, \" \", f_time, \" \", s_time, \" \", t_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a487c18",
   "metadata": {},
   "source": [
    "# GazeTracking 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52c7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_analysis(sensitivity, video_path):\n",
    "    # 라이브러리 gaze 클래스 초기화\n",
    "    gaze = GazeTracking()\n",
    "    \n",
    "    # 라이브러리 pose 클래스 초기화\n",
    "    mpPose = mp.solutions.pose\n",
    "    pose = mpPose.Pose()\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "    # 비디오 객체 불러오기\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if cap.isOpened()==False:\n",
    "        print(\"동영상 불러오기에 실패했습니다.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 변수 정의\n",
    "    FPS = int(cap.get(cv2.CAP_PROP_FPS)) # 동영상의 fps 알아냄\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # 전체 frame 수 알아냄\n",
    "    duration = frame_count/FPS # fps와 전체 frame 수로 동영상 길이 알아냄\n",
    "\n",
    "    # 자세가 바르지 않은 시간을 세는 변수\n",
    "    count = 0\n",
    "    \n",
    "    # 각 제스처의 시간을 세는 변수\n",
    "    first_count = 0 # 1번 제스처\n",
    "    second_count = 0 # 2번 제스처\n",
    "    third_count = 0 # 3번 제스처\n",
    "    face_count = 0 # 주변\n",
    "    movement_count = 0 # 얼굴\n",
    "    script_count = 0 # 대본\n",
    "    \n",
    "    # 프레임 변수\n",
    "    f_count = 0\n",
    "    \n",
    "    # 자세 불량 flag 변수\n",
    "    p_before = 0; p_present = 0\n",
    "\n",
    "    # 첫번째 제스처 flag 변수\n",
    "    f_before = 0; f_present = 0\n",
    "\n",
    "    # 두 번째 제스처 flag 변수\n",
    "    s_before = 0; s_present = 0\n",
    "\n",
    "    # 세 번째 제스처 flag 변수\n",
    "    t_before = 0; t_present = 0\n",
    "    \n",
    "    # face\n",
    "    face_before = 0; face_present = 0\n",
    "\n",
    "    # script\n",
    "    script_before = 0; script_present = 0\n",
    "\n",
    "    # face movement\n",
    "    movement_before = 0; movement_present = 0\n",
    "    \n",
    "    # 눈 깜박임 횟수 보정값\n",
    "    correction = duration / 20\n",
    "\n",
    "    # 분석 시작 시간\n",
    "    start = time.time()\n",
    "\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "\n",
    "        # 원하는 프레임 단위로 cut\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES,f_count/2);\n",
    "        f_count += FPS\n",
    "\n",
    "        # 동영상이 끝나면 break\n",
    "        if (np.shape(img) == ()): break\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(imgRGB)\n",
    "        \n",
    "\n",
    "        # 각 변수에 스켈레톤 저장\n",
    "        left_shoulder = results.pose_landmarks.landmark[11]\n",
    "        right_shoulder = results.pose_landmarks.landmark[12]\n",
    "\n",
    "        left_wrist = results.pose_landmarks.landmark[15]\n",
    "        right_wrist = results.pose_landmarks.landmark[16]\n",
    "\n",
    "        left_elbow = results.pose_landmarks.landmark[13]\n",
    "        right_elbow = results.pose_landmarks.landmark[14]\n",
    "\n",
    "        left_hip = results.pose_landmarks.landmark[23]\n",
    "        right_hip = results.pose_landmarks.landmark[24]\n",
    "\n",
    "        nose = results.pose_landmarks.landmark[0]\n",
    "        \n",
    "        \n",
    "        # 조건 잡아내기\n",
    "        if results.pose_landmarks:\n",
    "            mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "            \n",
    "            \n",
    "            # 1초 동안 그 행동을 했다고 판단하면 각 count 변수에 더하기\n",
    "            # FPS/2를 하는 이유는 프레임수를 FPS/2로 건너뛰었기 때문에\n",
    "            if p_before == p_present and p_present == 1:\n",
    "                count += FPS/2\n",
    "\n",
    "            if f_before == f_present and f_present == 1:\n",
    "                first_count += FPS/2\n",
    "\n",
    "            if s_before == s_present and s_present == 1:\n",
    "                second_count += FPS/2\n",
    "\n",
    "            if t_before == t_present and t_present == 1:\n",
    "                third_count += FPS/2\n",
    "                \n",
    "            if movement_before == movement_present and movement_present == 1:\n",
    "                movement_count += FPS/2\n",
    "\n",
    "            # 변수 초기화하기\n",
    "            p_before = p_present\n",
    "            f_before = f_present\n",
    "            s_before = s_present\n",
    "            t_before = t_present\n",
    "            movement_before = movement_present\n",
    "            \n",
    "            \n",
    "            # 얼굴 움직임 분석\n",
    "            if (abs(nose.x - 0.5) >= (11 - sensitivity) * 0.1):\n",
    "                movement_present = 1\n",
    "            else:\n",
    "                movement_present = 0\n",
    "\n",
    "\n",
    "            # 자세 분석\n",
    "            if (abs((left_shoulder.x + right_shoulder.x) / 2 - 0.5) >= 0.1):\n",
    "                print(\"몸을 화면 가운데에 맞춰주세요.\")\n",
    "\n",
    "            if (abs(left_shoulder.y - right_shoulder.y) >= (11 - sensitivity) * 0.01):\n",
    "                # print(\"두 어깨의 균형이 맞지 않습니다.\")\n",
    "                p_present = 1\n",
    "            else:\n",
    "                p_present = 0\n",
    "\n",
    "            # 제스처 분석\n",
    "    \n",
    "            # 1번: 손이 얼굴 위로 올라갔을 때\n",
    "            if ((left_wrist.x < left_shoulder.x) and (left_wrist.x > right_shoulder.x) \\\n",
    "               and (left_wrist.y < left_shoulder.y)):\n",
    "                f_present = 1\n",
    "\n",
    "            elif ((right_wrist.x < left_shoulder.x) and (right_wrist.x > right_shoulder.x) \\\n",
    "               and (right_wrist.y < right_shoulder.y)):\n",
    "                f_present = 1\n",
    "            else:\n",
    "                f_present = 0\n",
    "\n",
    "            # 2번: 팔짱 끼거나 한 쪽 팔을 잡았을 때, 손 맞잡을 때\n",
    "            if (abs(left_wrist.x - right_shoulder.x) <= sensitivity * 0.05 or abs(left_wrist.x - right_shoulder.x) <= sensitivity * 0.05):\n",
    "                s_present = 1\n",
    "            else:\n",
    "                s_present = 0\n",
    "\n",
    "            # 3번: 허리에 손을 올렸을 때\n",
    "            if (left_wrist.y < left_hip.y and right_wrist.y < right_hip.y):\n",
    "                if (abs(left_wrist.x - left_hip.x) <= sensitivity * 0.01 and (left_hip.y - left_wrist.y) <= sensitivity * 0.005 and abs(right_wrist.x - right_hip.x) <= sensitivity * 0.01 and (right_hip.y - right_wrist.y) <= sensitivity * 0.005):\n",
    "                    t_present = 1\n",
    "                else:\n",
    "                    t_present = 0\n",
    "\n",
    "                    \n",
    "                    \n",
    "        # We send this frame to GazeTracking to analyze it\n",
    "        gaze.refresh(img)\n",
    "        new_img = gaze.annotated_frame()\n",
    "\n",
    "        if movement_before == movement_present and movement_present == 1:\n",
    "            movement_count += FPS/2\n",
    "\n",
    "        if face_before == face_present and face_present == 1:\n",
    "            face_count += FPS/2\n",
    "\n",
    "        if script_before == script_present and script_present == 1:\n",
    "            script_count += FPS/2\n",
    "\n",
    "        face_before = face_present\n",
    "        script_before = script_present\n",
    "        movement_before = movement_present\n",
    "\n",
    "        if gaze.is_blinking():\n",
    "            script_present = 1\n",
    "        else:\n",
    "            script_present = 0\n",
    "\n",
    "        if gaze.is_right():\n",
    "            face_present = 1\n",
    "        elif gaze.is_left():\n",
    "            face_present = 1\n",
    "        else:\n",
    "            face_present = 0\n",
    "        \n",
    "        \n",
    "        cv2.namedWindow('pose', cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"pose\", img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    end = time.time()\n",
    "    cap.release()\n",
    "    cv2.destroyWindow(\"pose\")\n",
    "\n",
    "    minutes = int(duration / 60)\n",
    "    seconds = duration % 60\n",
    "\n",
    "    print(\"영상 길이 : \" + str(minutes) + ':' + str(seconds))\n",
    "    print(\"분석에 걸린 시간 : \", (end - start))\n",
    "    print(\"fps : \", FPS)\n",
    "\n",
    "    print(\"자세가 기울어진 시간 : \", count/FPS)\n",
    "    print(\"1번 제스처 시간 : \", first_count/FPS)\n",
    "    print(\"2번 제스처 시간 : \", second_count/FPS)\n",
    "    print(\"3번 제스처 시간 : \", third_count/FPS)\n",
    "    if (script_count/FPS - correction > 0):\n",
    "        print(\"시선이 분산된 시간(대본) : \", script_count/FPS - correction)\n",
    "    print(\"시선이 분산된 시간(주변) : \", face_count/FPS)\n",
    "    print(\"얼굴 움직임 시간 : \", movement_count/FPS)\n",
    "    \n",
    "    return count/FPS, first_count/FPS, second_count/FPS, third_count/FPS, script_count/FPS - correction, face_count/FPS, movement_count/FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5080df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "민감도를 입력해주세요.(1 ~ 10) : 10\n",
      "영상 길이 : 0:33.458333333333336\n",
      "분석에 걸린 시간 :  17.11694049835205\n",
      "fps :  24\n",
      "자세가 기울어진 시간 :  17.5\n",
      "1번 제스처 시간 :  2.5\n",
      "2번 제스처 시간 :  18.0\n",
      "3번 제스처 시간 :  9.5\n",
      "시선이 분산된 시간(주변) :  0.0\n",
      "얼굴 움직임 시간 :  9.5\n",
      "17.5   2.5   18.0   9.5   -1.6729166666666668   0.0   9.5\n"
     ]
    }
   ],
   "source": [
    "# 민감도는 1부터 10까지의 정수\n",
    "sensitivity = int(input(\"민감도를 입력해주세요.(1 ~ 10) : \"))\n",
    "video_path = 'C:/Users/82109/Videos/sample.mp4'\n",
    "\n",
    "pose_time, f_time, s_time, t_time, script_time, face_time, movement_time = video_analysis(sensitivity, video_path)\n",
    "print(pose_time, \" \", f_time, \" \", s_time, \" \", t_time, \" \", script_time, \" \", face_time, \" \", movement_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f03a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
